{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gpu정보 확인\n",
    "!nvidia-smi\n",
    "# watch nvidia-smi 커널에서 계속 확인\n",
    "# nvidia-smi -lms 실시간 확인\n",
    "# CUDA_VISIBLE_DEVICES=0 python3 file.py / GPU 0번만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'age': tf.FixedLenFeature([1], tf.int64),\n",
    "        'img': tf.FixedLenFeature([61*49], tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "    age = parsed_feature['age']\n",
    "    img = parsed_feature['img']\n",
    "    return age, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-9ced1003f4fe>:4: TFRecordDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.TFRecordDataset`.\n",
      "conv1 :  (?, 61, 49, 16)\n",
      "conv2 :  (?, 61, 49, 32)\n",
      "pool2 :  (?, 30, 24, 32)\n",
      "conv3 :  (?, 30, 24, 64)\n",
      "pool3 :  (?, 15, 12, 64)\n",
      "flat :  (?, 11520)\n",
      "fc1 :  (?, 5000)\n",
      "fc2 :  (?, 1000)\n",
      "out :  (?, 3)\n",
      "step: 0, loss: 34.97539138793945\n",
      "step: 1, loss: 10.511804580688477\n",
      "step: 2, loss: 2.8064095973968506\n",
      "step: 3, loss: 5.196539878845215\n",
      "step: 4, loss: 2.4722490310668945\n",
      "step: 5, loss: 2.581576108932495\n",
      "step: 6, loss: 2.278045177459717\n",
      "step: 7, loss: 2.3023054599761963\n",
      "step: 8, loss: 3.5663747787475586\n",
      "step: 9, loss: 2.8424630165100098\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = './cnn_dataset/face_train.tfrecord'\n",
    "test_data_dir = './cnn_dataset/face_test.tfrecord'\n",
    "\n",
    "train_dataset = tf.contrib.data.TFRecordDataset(train_data_dir).map(parser)\n",
    "train_dataset = train_dataset.shuffle(7777).batch(32)\n",
    "#train_dataset = train_dataset.repeat(10)\n",
    "itr = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "age, img = itr.get_next()\n",
    "\n",
    "\"\"\"\n",
    "이미지 잘들어오는지 확인\n",
    "with tf.Session() as sess:\n",
    "    _age, _img = sess.run([age, img])\n",
    "    print(_age)\n",
    "    print(_img)\n",
    "\"\"\"\n",
    "\n",
    "img = tf.reshape(img, [-1, 61, 49, 1])\n",
    "# int -> float (int 산술연산 잘 안되기 때문에 float으로 바꿔준다.)\n",
    "img = tf.cast(img, tf.float32)\n",
    "\n",
    "\n",
    "age = tf.reshape(age, [-1])\n",
    "age = tf.one_hot(age, depth=3, axis=-1, dtype = tf.float32)\n",
    "\n",
    "\"\"\"\n",
    "이미지 형태 확인\n",
    "with tf.Session() as sess:\n",
    "    _age, _img = sess.run([age, img])\n",
    "    print(_age)\n",
    "    print(_img)\n",
    "\"\"\"\n",
    "\n",
    "activation = tf.nn.relu\n",
    "reuse = tf.AUTO_REUSE\n",
    "#kernel_size 3 or [3, 3] 가로 세로 3 * 3\n",
    "conv1 = tf.layers.conv2d(img, filters=16, kernel_size=3, padding='SAME', \n",
    "                         activation=activation, reuse=reuse, name='conv1')\n",
    "print('conv1 : ', conv1.shape)\n",
    "conv2 = tf.layers.conv2d(conv1, filters=32, kernel_size=3, padding='SAME',\n",
    "                        activation=activation, reuse=reuse, name='conv2')\n",
    "print('conv2 : ', conv2.shape)\n",
    "#pool_size 얼마나 줄일꺼냐, strides 몇칸씩 이동?\n",
    "pool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)\n",
    "print('pool2 : ', pool2.shape)\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool2, filters=64, kernel_size=3, padding='SAME',\n",
    "                        activation=activation, reuse=reuse, name='conv3')\n",
    "print('conv3 : ', conv3.shape)\n",
    "\n",
    "pool3 = tf.layers.max_pooling2d(conv3, pool_size=2, strides=2)\n",
    "print('pool3 : ', pool3.shape)\n",
    "\n",
    "flat = tf.layers.flatten(pool3)\n",
    "print('flat : ', flat.shape)\n",
    "\n",
    "fc1 = tf.layers.dense(flat, 5000, activation=tf.nn.relu, reuse=reuse, name='fc1')\n",
    "print('fc1 : ', fc1.shape)\n",
    "fc2 = tf.layers.dense(fc1, 1000, activation=tf.nn.relu, reuse=reuse, name='fc2')\n",
    "print('fc2 : ', fc2.shape)\n",
    "out = tf.layers.dense(fc2, units=3, reuse=reuse, name='out')\n",
    "print('out : ', out.shape)\n",
    "\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(age, out)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-5).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        _, _loss = sess.run([train_op, loss])\n",
    "        print('step: {}, loss: {}'.format(i, _loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
