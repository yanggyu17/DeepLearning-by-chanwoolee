{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "nbviewer.jupyter.org/format/slides/gist/leechanwoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Day 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## High Level APIs\n",
    " * Estimator\n",
    " * Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Estimator\n",
    " * sklearn의 estimator와 유사하게 설계된 framework\n",
    " * train, evaluate, predict 등을 쉽게 구현 할 수 있음.\n",
    " * Session을 사용자가 직접 구현 할 필요 없음\n",
    " * input pipeline만 작성하면 model 설계에 집중 할 수 있다.\n",
    " * model export를 제공하며 serving시 필요한 protocol buffer file을 생성해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### input function\n",
    "\n",
    " * model에 투입되는 dataset을 load하는 pipeline을 구성하는 함수 정의\n",
    " * 원하는 pipeline을 설계하고, 함수의 리턴은 train, labels로만 해주면 사용 가능\n",
    " * Estimator에서 이 input function을 함수형으로 받기 때문에 입력 argument 필요시 아래 코드와 같이 lambda 식 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'age': tf.FixedLenFeature([1], tf.int64),\n",
    "        'img': tf.FixedLenFeature([61*49], tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "    age = parsed_feature['age']\n",
    "    img = parsed_feature['img']\n",
    "    return age, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def input_fn(dataset_dir, batch_size):\n",
    "    dataset = tf.contrib.data.TFRecordDataset(dataset_dir).map(parser)\n",
    "    dataset = dataset.batch(batch_size).shuffle(7777)\n",
    "    \n",
    "    itr = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    age, img = itr.get_next()\n",
    "    \n",
    "    img = tf.reshape(img, [-1, 61, 49, 1])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    \n",
    "    age = tf.reshape(age, [-1])\n",
    "    age_onehot = tf.one_hot(age, depth=3, axis=-1)\n",
    "    \n",
    "    return {'img': img}, {'age': age, 'age_onehot': age_onehot}\n",
    "    \n",
    "\n",
    "def get_train_input_fn():\n",
    "    return lambda: input_fn('./cnn_dataset/face_train.tfrecord', 10)\n",
    "\n",
    "def get_test_input_fn():\n",
    "    return lambda: input_fn('./cnn_dataset/face_test.tfrecord', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### model function\n",
    "\n",
    " * 실제 모델이 들어가는 함수로써 입력인자(features, labels, mode) signature를 지켜주어야 한다.\n",
    " * 이 model function도 마찬가지로 사용자의 hyper parameters를 외부에서 제어 할 수 있도록 lambda식을 사용하여 입력인자로 넘겨 받을 수 있다.\n",
    " * 반드시 EstimatorSpec를 리턴시켜주어야 하며, TRAIN, EVAL, PREDICT 모드 별 트레인 모델을 분기문으로 나눠준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def model(features, labels, mode, **params):\n",
    "    conv1 = tf.layers.conv2d(features['img'], filters=10, kernel_size=3, \n",
    "                             padding='SAME', activation=params['activation'])\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2)\n",
    "    conv2 = tf.layers.conv2d(pool1, filters=10, kernel_size=3, \n",
    "                             padding='SAME', activation=params['activation'])\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)\n",
    "    conv3 = tf.layers.conv2d(pool2, filters=10, kernel_size=3, \n",
    "                             padding='SAME', activation=params['activation'])\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, pool_size=2, strides=2)\n",
    "\n",
    "    flat_size = int(pool3.shape[1]) * int(pool3.shape[2]) * int(pool3.shape[3])\n",
    "    flat = tf.reshape(pool3, [-1, flat_size])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dropout_prob = params['dropout_prob']\n",
    "    else:\n",
    "        dropout_prob = 1\n",
    "    \n",
    "\n",
    "    dropout1 = tf.layers.dropout(flat, dropout_prob)\n",
    "    fc1 = tf.layers.dense(dropout1, 1000)\n",
    "\n",
    "    dropout2 = tf.layers.dropout(fc1, dropout_prob)\n",
    "    out = tf.layers.dense(dropout2, 3) \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        loss = tf.losses.softmax_cross_entropy(labels['age_onehot'], out)\n",
    "        train_op = tf.train.GradientDescentOptimizer(1e-6).minimize(loss, global_step)\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(train_op=train_op, loss=loss, mode=mode)\n",
    "\n",
    "        \n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.losses.softmax_cross_entropy(labels['age_onehot'], out)\n",
    "        \n",
    "        pred = tf.argmax(tf.nn.softmax(out), axis=1)\n",
    "        accuracy = tf.metrics.accuracy(labels['age'], pred)\n",
    "        eval_metric_ops = {\"acc\": accuracy} \n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "    else:\n",
    "        estimator_spec = None\n",
    "        \n",
    "    return estimator_spec\n",
    "\n",
    "def get_model_fn(activation, dropout_prob):\n",
    "    return lambda features, labels, mode: model(features, labels, mode, \n",
    "                                                activation=activation, dropout_prob=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Estimator\n",
    "\n",
    " * 아래와 같이 model 함수를 이용하여 Estimator를 생성해준다.\n",
    " * 생성한 Estimator 이용하여 train, eval, predict 등을 수행 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x115b742e8>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_save_summary_steps': 100, '_evaluation_master': '', '_master': '', '_session_config': None, '_environment': 'local', '_is_chief': True, '_num_worker_replicas': 0, '_model_dir': './logs/estimator', '_task_id': 0, '_task_type': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-6001\n",
      "INFO:tensorflow:Saving checkpoints for 6002 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.17684, step = 6002\n",
      "INFO:tensorflow:global_step/sec: 68.3415\n",
      "INFO:tensorflow:loss = 1.27675, step = 6102 (1.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5664\n",
      "INFO:tensorflow:loss = 0.844532, step = 6202 (1.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1978\n",
      "INFO:tensorflow:loss = 1.04935, step = 6302 (1.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1414\n",
      "INFO:tensorflow:loss = 1.28345, step = 6402 (1.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9065\n",
      "INFO:tensorflow:loss = 0.820354, step = 6502 (1.452 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6601 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.349178.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-16-15:48:36\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-6601\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-16-15:48:37\n",
      "INFO:tensorflow:Saving dict for global step 6601: acc = 0.492498, global_step = 6601, loss = 1.39988\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-6601\n",
      "INFO:tensorflow:Saving checkpoints for 6602 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.87919, step = 6602\n",
      "INFO:tensorflow:global_step/sec: 65.7797\n",
      "INFO:tensorflow:loss = 0.760529, step = 6702 (1.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3511\n",
      "INFO:tensorflow:loss = 1.00407, step = 6802 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.2456\n",
      "INFO:tensorflow:loss = 0.326808, step = 6902 (1.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.58\n",
      "INFO:tensorflow:loss = 0.96353, step = 7002 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3555\n",
      "INFO:tensorflow:loss = 0.414311, step = 7102 (1.421 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7201 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.56244.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-16-15:48:49\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-7201\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-16-15:48:50\n",
      "INFO:tensorflow:Saving dict for global step 7201: acc = 0.484018, global_step = 7201, loss = 1.3787\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-7201\n",
      "INFO:tensorflow:Saving checkpoints for 7202 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1452, step = 7202\n",
      "INFO:tensorflow:global_step/sec: 68.1717\n",
      "INFO:tensorflow:loss = 0.730702, step = 7302 (1.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6265\n",
      "INFO:tensorflow:loss = 1.26689, step = 7402 (1.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3493\n",
      "INFO:tensorflow:loss = 1.00017, step = 7502 (1.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8502\n",
      "INFO:tensorflow:loss = 0.831771, step = 7602 (1.566 sec)\n"
     ]
    }
   ],
   "source": [
    "est_config = tf.estimator.RunConfig()\n",
    "est = tf.estimator.Estimator(model_fn=get_model_fn(activation=tf.nn.relu, dropout_prob=0.7), \n",
    "                             model_dir='./logs/estimator',\n",
    "                             config=config)\n",
    "\n",
    "for epoch in range(3):\n",
    "    est.train(get_train_input_fn())\n",
    "    est.evaluate(get_test_input_fn())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiment\n",
    " * estimator를 기가막히게 돌려주는 framework\n",
    " * local distributed setting만 되어 있다면 분산러닝 자동 지원\n",
    " * training, inference, predict 모델을 따로 저장하기 때문에 serving 시 Experiment를 통한 export 권장\n",
    " * 내부에 학습간 필요한 기능들을 다수 내장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x115b3e588>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_save_summary_steps': 100, '_evaluation_master': '', '_master': '', '_session_config': None, '_environment': 'local', '_is_chief': True, '_num_worker_replicas': 0, '_model_dir': './logs/estimator', '_task_id': 0, '_task_type': None}\n",
      "WARNING:tensorflow:From /Users/chanwoo/anaconda/envs/tensorflow-py3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-5401\n",
      "INFO:tensorflow:Saving checkpoints for 5402 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-16-15:45:29\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-5402\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-16-15:45:30\n",
      "INFO:tensorflow:Saving dict for global step 5402: acc = 0.472, global_step = 5402, loss = 1.45123\n",
      "INFO:tensorflow:Validation (step 5402): loss = 1.45123, global_step = 5402, acc = 0.472\n",
      "INFO:tensorflow:loss = 1.12171, step = 5402\n",
      "INFO:tensorflow:global_step/sec: 25.2029\n",
      "INFO:tensorflow:loss = 2.16686, step = 5502 (1.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.801\n",
      "INFO:tensorflow:loss = 0.589146, step = 5602 (1.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.1881\n",
      "INFO:tensorflow:loss = 0.890765, step = 5702 (1.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.4764\n",
      "INFO:tensorflow:loss = 2.06711, step = 5802 (1.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2995\n",
      "INFO:tensorflow:loss = 2.79375, step = 5902 (1.531 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into ./logs/estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.11913.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-16-15:45:41\n",
      "INFO:tensorflow:Restoring parameters from ./logs/estimator/model.ckpt-6001\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-16-15:45:42\n",
      "INFO:tensorflow:Saving dict for global step 6001: acc = 0.523666, global_step = 6001, loss = 1.31787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'acc': 0.52366567, 'global_step': 6001, 'loss': 1.3178735}, [])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "def get_experiment(output_dir):\n",
    "    os.environ['TF_CONFIG'] = json.dumps({'environment': 'local'})\n",
    "    config = tf.contrib.learn.RunConfig()\n",
    "    return tf.contrib.learn.Experiment(estimator=tf.estimator.Estimator(model_fn=get_model_fn(activation=tf.nn.relu,\n",
    "                                                                                              dropout_prob=0.7), \n",
    "                                                                        model_dir=output_dir,\n",
    "                                                                        config=config),\n",
    "                                       train_input_fn=get_train_input_fn(),\n",
    "                                       eval_input_fn=get_test_input_fn())\n",
    "\n",
    "tf.contrib.learn.learn_runner.run(experiment_fn=get_experiment, output_dir='./logs/estimator')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
