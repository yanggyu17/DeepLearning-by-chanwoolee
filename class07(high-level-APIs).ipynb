{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#순서가 중요 앞부분 features, 뒷부분 labels\n",
    "def input_fn():\n",
    "    return features, labels\n",
    "    #return features, {'label1' : label1, 'label2' : label2}\n",
    "    \n",
    "def model_fn(features, labels, mode):\n",
    "    return tf.estimator.EstimatorSpec(mode, train_op, loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_service': None, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_model_dir': './cnn_models_B/', '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1179c1f60>, '_save_checkpoints_secs': 600, '_master': '', '_task_id': 0, '_session_config': None, '_num_worker_replicas': 1, '_save_checkpoints_steps': None}\n",
      "(?, 61, 49, 16)\n",
      "(?, 61, 49, 32)\n",
      "(?, 30, 24, 32)\n",
      "(?, 30, 24, 64)\n",
      "(?, 15, 12, 64)\n",
      "(?, 11520)\n",
      "(?, 1000)\n",
      "(?, 200)\n",
      "(?, 3)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'age' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7a20d05706f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mcnn_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./cnn_models_B/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mcnn_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0mcnn_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0m_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-7a20d05706f5>\u001b[0m in \u001b[0;36mcnn_model\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mestimator_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         estimator_spec = tf.estimator.EstimatorSpec(mode=mode,\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'age' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'age': tf.FixedLenFeature([1], tf.int64),\n",
    "        'img': tf.FixedLenFeature([61*49], tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "    age = parsed_feature['age']\n",
    "    img = parsed_feature['img']\n",
    "    return age, img\n",
    "\n",
    "train_data_dir = './cnn_dataset/face_train.tfrecord'\n",
    "test_data_dir = './cnn_dataset/face_test.tfrecord'\n",
    "batch_size = 32\n",
    "\n",
    "def get_input_fn(data_dir, batch_size):\n",
    "    return lambda: input_fn(data_dir, batch_size)\n",
    "\n",
    "def input_fn(data_dir, batch_size):\n",
    "    dataset = tf.contrib.data.TFRecordDataset(data_dir).map(parser)\n",
    "    dataset = train_dataset.shuffle(7777)\n",
    "    dataset = train_dataset.batch(batch_size)\n",
    "    \n",
    "    itr = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    age, img = itr.get_next()\n",
    "    \n",
    "    img = tf.reshape(img, [-1, 61, 49, 1])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    age = tf.reshape(age, [-1])\n",
    "    age = tf.one_hot(age, depth=3, axis=-1, dtype=tf.float32)\n",
    "    \n",
    "    return img, age\n",
    "\n",
    "\n",
    "def cnn_model(features, labels, mode):\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PRED = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(features, \n",
    "                             filters=16, \n",
    "                             kernel_size=4, \n",
    "                             padding='same', \n",
    "                             activation=tf.nn.relu,  \n",
    "                             name='conv1')\n",
    "    print(conv1.shape)\n",
    "    conv2 = tf.layers.conv2d(conv1,\n",
    "                            filters=32,\n",
    "                            kernel_size=3,\n",
    "                            padding='same',\n",
    "                            activation=tf.nn.relu,\n",
    "                            name='conv2')\n",
    "    print(conv2.shape)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)\n",
    "    print(pool2.shape)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(pool2,\n",
    "                            filters=64,\n",
    "                            kernel_size=3,\n",
    "                            padding='same',\n",
    "                            activation=tf.nn.relu,\n",
    "                            name='conv3')\n",
    "    print(conv3.shape)\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, pool_size=2, strides=2)\n",
    "    print(pool3.shape)\n",
    "\n",
    "    flat = tf.layers.flatten(pool3)\n",
    "    print(flat.shape)\n",
    "\n",
    "    fc1 = tf.layers.dense(flat, \n",
    "                          units=1000, \n",
    "                          activation=tf.nn.relu, \n",
    "                          name='fc1')\n",
    "    \n",
    "    drop1 = tf.layers.dropout(fc1, 0.3, training=TRAIN)\n",
    "\n",
    "    print(fc1.shape)\n",
    "    fc2 = tf.layers.dense(drop1,\n",
    "                         units=200,\n",
    "                         activation=tf.nn.relu,\n",
    "                         name='fc2')\n",
    "    print(fc2.shape)\n",
    "    \n",
    "    drop2 = tf.layers.dropout(fc2, 0.3, training=TRAIN)\n",
    "\n",
    "    out = tf.layers.dense(drop2,\n",
    "                         units=3,\n",
    "                         name='out')\n",
    "    print(out.shape)\n",
    "    global_step = tf.train.get_global_step()\n",
    "    \n",
    "    estimator_spec = None\n",
    "    if TRAIN:\n",
    "        loss = tf.losses.softmax_cross_entropy(age, out)\n",
    "        train_op = tf.train.GradientDescentOptimizer(1e-5).minimize(loss, global_step)\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                     loss=loss,\n",
    "                                     train_op=train_op)\n",
    "    elif EVAL:\n",
    "        loss = tf.losses.softmax_cross_entropy(age, out) \n",
    "        pred = tf.nn.softmax(out)\n",
    "        accuracy = tf.metrics.accuracy(tf.argmax(labels, 1), tf.argmax(pred, 1))\n",
    "        eval_metric_ops = {'acc' : accuracy}\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                     loss=loss,\n",
    "                                     eval_metric_ops=eval_metric_ops)\n",
    "    elif PRED:\n",
    "        prob = tf.nn.softmax(out)\n",
    "        age = tf.argmax(prob, axis=1)\n",
    "        pred = {'img' : img, 'prob' : prob, 'age' : age}\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                                   predictions=pred)\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise Exception('estimator spec is None')\n",
    "        \n",
    "    return estimator_spec\n",
    "\n",
    "\n",
    "cnn_estimator = tf.estimator.Estimator(cnn_model, model_dir='./cnn_models_B/')\n",
    "cnn_estimator.train(get_input_fn(train_data_dir, batch_size))\n",
    "cnn_estimator.evaluate(get_input_fn(test_data_dir, batch_size))\n",
    "_preds = cnn_estimator.predict(get_input_fn(test_data_dir, batch_size))\n",
    "\n",
    "for p in _preds:\n",
    "    print(p['prob'], p['age'])\n",
    "    img = np.mean(p['img'], axis=-1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     pred = tf.nn.softmax(test_out)\n",
    "#     accuracy = tf.metrics.accuracy(tf.argmax(age, 1), tf.argmax(pred, 1))\n",
    "\n",
    "# tf.summary.scalar('loss', loss)\n",
    "# for v in tf.trainable_variables():\n",
    "#     tf.summary.histogram('var_{}'.format(v.name), v)\n",
    "\n",
    "# merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/9f/r85pl3x54ysbtzyrt_jv00y40000gn/T/tmphxsjswu2\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_service': None, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_model_dir': '/var/folders/9f/r85pl3x54ysbtzyrt_jv00y40000gn/T/tmphxsjswu2', '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x117acacc0>, '_save_checkpoints_secs': 600, '_master': '', '_task_id': 0, '_session_config': None, '_num_worker_replicas': 1, '_save_checkpoints_steps': None}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find trained model in model_dir: /var/folders/9f/r85pl3x54ysbtzyrt_jv00y40000gn/T/tmphxsjswu2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-280e225bd0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mcnn_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# cnn_estimator.train(get_input_fn(train_data_dir, batch_size))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mcnn_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlatest_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         raise ValueError('Could not find trained model in model_dir: {}.'.\n\u001b[0;32m--> 797\u001b[0;31m                          format(self._model_dir))\n\u001b[0m\u001b[1;32m    798\u001b[0m       \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find trained model in model_dir: /var/folders/9f/r85pl3x54ysbtzyrt_jv00y40000gn/T/tmphxsjswu2."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'age': tf.FixedLenFeature([1], tf.int64),\n",
    "        'img': tf.FixedLenFeature([61*49], tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "    age = parsed_feature['age']\n",
    "    img = parsed_feature['img']\n",
    "    return age, img\n",
    "\n",
    "train_data_dir = './cnn_dataset/face_train.tfrecord'\n",
    "test_data_dir = './cnn_dataset/face_test.tfrecord'\n",
    "batch_size = 32\n",
    "\n",
    "def get_input_fn(data_dir, batch_size):\n",
    "    return lambda: input_fn(data_dir, batch_size)\n",
    "\n",
    "def input_fn(data_dir, batch_size):\n",
    "    dataset = tf.contrib.data.TFRecordDataset(data_dir).map(parser)\n",
    "    dataset = dataset.shuffle(7777)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    itr = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    age, img = itr.get_next()\n",
    "    \n",
    "    img = tf.reshape(img, [-1, 61, 49, 1])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    age = tf.reshape(age, [-1])\n",
    "    age = tf.one_hot(age, depth=3, axis=-1, dtype=tf.float32)\n",
    "\n",
    "    return img, age\n",
    "\n",
    "\n",
    "\n",
    "def cnn_model(features, labels, mode):\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PRED = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(features, \n",
    "                             filters=16,\n",
    "                             kernel_size=4, \n",
    "                             padding='same', \n",
    "                             activation=tf.nn.relu, \n",
    "                             name='conv1')\n",
    "    print(conv1.shape)\n",
    "    conv2 = tf.layers.conv2d(conv1,\n",
    "                            filters=32,\n",
    "                            kernel_size=3,\n",
    "                            padding='same',\n",
    "                            activation=tf.nn.relu,\n",
    "                            name='conv2')\n",
    "    print(conv2.shape)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)\n",
    "    print(pool2.shape)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(pool2,\n",
    "                            filters=64,\n",
    "                            kernel_size=3,\n",
    "                            padding='same',\n",
    "                            activation=tf.nn.relu,\n",
    "                            name='conv3')\n",
    "    print(conv3.shape)\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, pool_size=2, strides=2)\n",
    "    print(pool3.shape)\n",
    "\n",
    "    flat = tf.layers.flatten(pool3)\n",
    "    print(flat.shape)\n",
    "\n",
    "    fc1 = tf.layers.dense(flat, \n",
    "                          units=1000, \n",
    "                          activation=tf.nn.relu, \n",
    "                          name='fc1')\n",
    "    \n",
    "    drop1 = tf.layers.dropout(fc1, 0.3, training=TRAIN)\n",
    "\n",
    "    print(fc1.shape)\n",
    "    fc2 = tf.layers.dense(drop1,\n",
    "                         units=200,\n",
    "                         activation=tf.nn.relu,\n",
    "                         name='fc2')\n",
    "    print(fc2.shape)\n",
    "    \n",
    "    drop2 = tf.layers.dropout(fc2, 0.3, training=TRAIN)\n",
    "\n",
    "    out = tf.layers.dense(drop2,\n",
    "                         units=3,\n",
    "                         name='out')\n",
    "    print(out.shape)\n",
    "    \n",
    "    global_step = tf.train.get_global_step()\n",
    "    \n",
    "    estimator_spec = None\n",
    "    if TRAIN:\n",
    "        loss = tf.losses.softmax_cross_entropy(labels, out)\n",
    "        train_op = tf.train.GradientDescentOptimizer(1e-5).minimize(loss, global_step)\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                     loss=loss,\n",
    "                                     train_op=train_op)\n",
    "    elif EVAL:\n",
    "        loss = tf.losses.softmax_cross_entropy(labels, out)\n",
    "        pred = tf.nn.softmax(out)\n",
    "        accuracy = tf.metrics.accuracy(tf.argmax(labels, 1), tf.argmax(pred, 1))\n",
    "        eval_metric_ops = {'acc': accuracy}\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                     loss=loss,\n",
    "                                     eval_metric_ops=eval_metric_ops)\n",
    "    else:\n",
    "        raise Exception('Estimator spec is None')\n",
    "\n",
    "    return estimator_spec\n",
    "\n",
    "cnn_estimator = tf.estimator.Estimator(cnn_model, model_dir='./cnn_models_B/')\n",
    "# cnn_estimator.train(get_input_fn(train_data_dir, batch_size))\n",
    "cnn_estimator.evaluate(get_input_fn(test_data_dir, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "str_list = '1 2 3 4 5 6 7'.split(' ')\n",
    "print(str_list[0])\n",
    "\n",
    "int_list = []\n",
    "for i in str_list:\n",
    "    int_list.append(int(i))\n",
    "print(int_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "int_list = list(map(int, str_list))\n",
    "print(int_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(x):\n",
    "    return x + 10\n",
    "\n",
    "print(add(5))\n",
    "\n",
    "list(map(add, [1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 12, 16, 20, 24]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mul(x):\n",
    "    return x * 4\n",
    "\n",
    "list(map(mul, [1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25, 36]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = lambda x: x*x\n",
    "\n",
    "list(map(power, [1, 2, 3, 4, 5, 6]))\n",
    "list(map(lambda x: x*x, [1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "<function equation.<locals>.<lambda> at 0x117c5e2f0>\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "def equation(w, b):\n",
    "    return lambda x: x*w + b\n",
    "\n",
    "print(equation(3, 5)(1))\n",
    "\n",
    "linear = equation(3, 5)\n",
    "print(linear)\n",
    "result = linear(2)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
